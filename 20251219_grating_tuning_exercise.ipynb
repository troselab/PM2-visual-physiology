{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0c6e0b-67d1-4e29-be9b-18de403f312f",
   "metadata": {},
   "source": [
    "##### in this notebook, we will look at the dataset of the neural activity in mouse V1 with grating stimuli and behavior monitor (running speed and pupil size) including the following practice:\n",
    "1. data loading, normalizing and synchronization\n",
    "2. exploring the relation between neural activity and behaviors\n",
    "3. visualizing event triggered neural activity\n",
    "4. orientation tuning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59863b9c-ad7b-4e5b-ac22-b9ff074337d4",
   "metadata": {},
   "source": [
    "# 0. Downloading data and installing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472f486",
   "metadata": {},
   "source": [
    "### Installing dependencies\n",
    "\n",
    "Execute the cell below to install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b5924-4088-48de-b99b-6043ec0e13ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Data import\n",
    "Here we need to download all the 5 files from sciebo link and load them in this notebook: \n",
    "* ***activity.npy***, neural activity (fluorescence) for XX cells across 38100 frames \n",
    "* ***stimulus_events.npy***, event onset and offset timestamp for each stimulus, \n",
    "* ***pupil_size.npy***, pupil size (diameter), one row for pupil size, one row for corresponding time\n",
    "* ***running_speed.npy***, running speed,one row for running speed, one row for corresponding time\n",
    "* ***bench2p_frame_times.npy***, timestamp for each frame of neural activity.\n",
    "* \n",
    "**If you execute the cell below, the files will be downloaded automatically**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "files = [\n",
    "    \"activity.npy\",\n",
    "    \"stimulus_events.npy\",\n",
    "    \"pupil_size.npy\",\n",
    "    \"running_speed.npy\",\n",
    "    \"bench2p_frame_times.npy\",\n",
    "]\n",
    "\n",
    "base_url = \"https://uni-bonn.sciebo.de/s/pD79oxy9cWRem6n/download?path=/&files=\"\n",
    "\n",
    "for fname in files:\n",
    "    url = base_url + fname\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    print(f\"Downloaded {fname}, {len(r.content)/1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2789c",
   "metadata": {},
   "source": [
    "To verify that this worked, let's import the packages and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65e982-438d-448e-84df-8394b3e86cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "### to load neural activity as numpy array\n",
    "neural_data = np.load('activity.npy',  allow_pickle=True)\n",
    "np.shape(neural_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a53b2",
   "metadata": {},
   "source": [
    "# 1. Normalization and synchronizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25804199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first some frames of neural activity - play around with start and stop and scale of the colorbar\n",
    "start = 0\n",
    "stop = 5000\n",
    "plt.imshow(neural_data[:,start:stop], aspect='auto')\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('neurons')\n",
    "# plt.xlim(200,4000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbcf4c5",
   "metadata": {},
   "source": [
    "#### Calcium signal normalization\n",
    "Calcium imaging data often contains variability due to experimental conditions, individual neuron activity baselines, and overall fluorescence intensity. Therefore, to standardize the signals, we will use z-score normalization to transforma the calcium signal to have mean of 0 and standard deviation of 1. The normalized signal is calculated as:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\text{x} $ is the original signal value.\n",
    "- $\\mu $ is the mean of the signal.\n",
    "- $\\sigma $ is the standard deviation of the signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959d4b0",
   "metadata": {},
   "source": [
    "### Task1.1: Normalize the neural activity using above formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1168aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write you own code\n",
    "### hint: use np.mean and np.std with axis=1 to normalize each neuron's activity\n",
    "\n",
    "neural_data_norm = \n",
    "\n",
    "#/.../\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb315b-5fe2-4824-923c-2826b4ba7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = 5000\n",
    "# plt.imshow(neural_data_norm[:,start:stop], aspect='auto')\n",
    "plt.imshow(neural_data_norm[:,start:stop], aspect='auto', vmin=-1, vmax=2) # change the range of the colorbar to see the activity better\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('neurons')\n",
    "# plt.xlim(200,4000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04445a2-ae8b-4c53-985c-ca38822f22c5",
   "metadata": {},
   "source": [
    "### Task1.2: plot the activity of a single neuron after z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08396ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your own code\n",
    "neuron_id = \n",
    "#/...enter you code here/#\n",
    "\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Neural Activity')\n",
    "plt.title(f'Neural Activity Trace for Neuron {neuron_id}')\n",
    "plt.xlim(start, stop)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e83cf2-3101-4aaf-b7dc-03e900757d65",
   "metadata": {},
   "source": [
    "Let's keep loading other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5844aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load stimulus_events as numpy array\n",
    "stimulus_events_file = np.load('stimulus_events.npy',  allow_pickle=True)\n",
    "print(\"To inspect the stimulus_events file, we print one column: \", stimulus_events_file[:,1])\n",
    "stim = stimulus_events_file[0] # grating direction\n",
    "stim_on = stimulus_events_file[1] # stimulus onset time\n",
    "stim_off = stimulus_events_file[2] # stimulus offset time\n",
    "# convert string into number\n",
    "stim = np.array([int(item.split(':')[1]) for item in stim], dtype=int)\n",
    "stim_on = np.array(stim_on, dtype=float)\n",
    "stim_off = np.array(stim_off, dtype=float)\n",
    "\n",
    "print(\"the shape for stimulus_events array is \", np.shape(stim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4eb262",
   "metadata": {},
   "source": [
    "load file for pupil size and running speed as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load pupil_size as numpy array\n",
    "pupil_size_file = np.load('pupil_size.npy',  allow_pickle=True)\n",
    "pupil_size = pupil_size_file[0]\n",
    "pupil_time = pupil_size_file[1]\n",
    "print(\"the shape for pupil_size array is \", np.shape(pupil_size))\n",
    "\n",
    "# to load running_speed as numpy array\n",
    "running_speed_file = np.load('running_speed.npy',  allow_pickle=True)\n",
    "running_speed = running_speed_file[0]\n",
    "running_time = running_speed_file[1]\n",
    "print(\"the shape for running_speed array is \", np.shape(running_speed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3330c",
   "metadata": {},
   "source": [
    "Now we could check the behavior data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(pupil_time, pupil_size)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Pupil Size (a.u.)\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(running_time, running_speed)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Running Speed (a.u.)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86191d53-b16c-4c9d-a7c2-bf6371c9848a",
   "metadata": {},
   "source": [
    "#### Data sychronization\n",
    "These files are all recorded simultaneously for 21min, but you may have already noticed that they are not in the same time length. This is because in different type of recording, we usually have different sampling rate with different devices, e.g. two-photon imaging here is recorded in 30Hz, pupil size is recorded in 60Hz. Therefore, for the convenience of analysis, we will synchronize/align these data into same time unit. There are multiple ways to do data synchronization. Here we would like to focus on neural acitvity related analysis, we will align the timestamps in the other 3 files according to neural activity frames by assigning the closest timestamps. And in the end of the synchronization part, we will get arrays with same length for neural activity, running speed, pupil size; and the event onset & offset will be the corresponding frame number. \n",
    "\n",
    "To do this, we will load one more file ***bench2p_frame_times.npy*** to get the corresponding timestamp for each frame of neural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2d9c4-fb0d-4142-8bd7-b97fb2a28fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_frame_time = np.load('bench2p_frame_times.npy',  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de00ac9-ad83-4e05-b548-016d467ac135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the timestamps for different types of data\n",
    "time = 10 # to show 10 sec time window\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.eventplot(neural_frame_time[neural_frame_time < time], lineoffsets=4)\n",
    "plt.eventplot(stim_on[stim_on < time], lineoffsets=3)\n",
    "plt.eventplot(stim_off[stim_off < time], lineoffsets=2)\n",
    "plt.eventplot(pupil_time[pupil_time < time], lineoffsets=1)\n",
    "plt.eventplot(running_time[running_time < time], lineoffsets=0)\n",
    "\n",
    "plt.yticks([0,1,2,3,4],[\"running\",\"pupil\",\"stim_off\",\"stim_on\",\"neural_activity\"])\n",
    "plt.xlabel(\"time (s)\")\n",
    "# plt.xlim(4, 4.5) # to zoom in\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to align stimulus timestamp with the neural activity timestamp\n",
    "def get_closest_timestamps_stim(stim_timestamps, target_timestamps):\n",
    "    # Find the closest index in `stim_timestamps` for each `target_timestamp`\n",
    "    aligned_indices = np.array([np.abs(target_timestamps - t).argmin() for t in stim_timestamps])\n",
    "\n",
    "    return aligned_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb96568",
   "metadata": {},
   "source": [
    "here we align the neural activity with stimulus on and off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_durations = 3 # duration of each stimulus trial is 3 sec\n",
    "neural_fs = 30 # sampling rate for neural activity\n",
    "\n",
    "stim_on_aligned = get_closest_timestamps_stim(stim_on, neural_frame_time)\n",
    "stim_off_aligned = stim_on_aligned + stim_durations * neural_fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_timestamps_behav(behav_timestamps, target_timestamps):\n",
    "    # similarly, we can align the neural activity timestamp with the other data timestamp\n",
    "    # aligned_indices = np.array([np.abs(behav_timestamps - t).argmin() for t in target_timestamps])\n",
    "\n",
    "    # to avoid repeat searching, we can use the following code by tracking the searching pointer\n",
    "    aligned_indices = []\n",
    "    j = 0  # Searching pointer\n",
    "    for t in target_timestamps:\n",
    "        # Move forward in behav_timestamps to find the closest timestamp\n",
    "        while j < len(behav_timestamps) - 1 and abs(behav_timestamps[j + 1] - t) < abs(behav_timestamps[j] - t):\n",
    "            j += 1\n",
    "        aligned_indices.append(j)\n",
    "\n",
    "    return np.array(aligned_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ab6d6",
   "metadata": {},
   "source": [
    "### Task1.3: align pupil_size and running_speed with neural activity respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your own code\n",
    "### hint 1. get the aligned frames using above function: get_closest_timestamps_behav()\n",
    "### hint 2. use the aligned frames to get corresponding data from original data array\n",
    "\n",
    "#/.../\n",
    "\n",
    "pupil_size_aligned =\n",
    "running_speed_aligned ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189113c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(pupil_size_aligned), np.shape(running_speed_aligned), np.shape(neural_data_norm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for the alignment\n",
    "# neural_frame_time[stim_on_aligned] - stim_on, (pupil_time_aligned - neural_frame_time)[stim_on_aligned[0]:stim_off_aligned[-1]], (running_time_aligned - neural_frame_time)[stim_on_aligned[0]:stim_off_aligned[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d607bd-1aee-4eca-89b0-c0977db64dcb",
   "metadata": {},
   "source": [
    "# 2. exploring the relation between neural activity and behaviors\n",
    "It has been shown that the neural activity can be modulated by behaviors. Here we will explolre how pupil size and running speed is related to neural activity in V1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate the correlation between neural activity and pupil size\n",
    "neural_activity_mean = np.average(neural_data_norm[:,stim_on_aligned[0]:stim_off_aligned[-1]], axis =0)\n",
    "\n",
    "corr_neural_pupil = np.corrcoef(neural_activity_mean, pupil_size_aligned[stim_on_aligned[0]:stim_off_aligned[-1]])\n",
    "corr_neural_pupil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac477d3b",
   "metadata": {},
   "source": [
    "### Task2: calculate the correlation among neural activity, running speed and pupil size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5fc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your own code \n",
    "### hint: use the same method as above: np.corrcoef()\n",
    "\n",
    "#/.../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f183ec-f07d-4b68-8f12-968575d02161",
   "metadata": {},
   "source": [
    "# 3. visualizing event-triggered neural activity\n",
    "The provided neural activity data is consists of 12 grating directions * 15 repeats of each directions. To analyze the event-triggered neural activity, we need to extract the corresponding neural activity for the same grating directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b06ed1",
   "metadata": {},
   "source": [
    "Here are two example trials for a neuron with 1s (30 frames) before stimulus onset and 1s after stimulus off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd42c96-9c15-476f-ba55-7c1d8adc33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neuron_id = 0\n",
    "trial_id_1 = 0\n",
    "trial_id_2 = 1\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(neural_data_norm[neuron_id,stim_on_aligned[trial_id_1]-30:stim_off_aligned[trial_id_1]+30])\n",
    "plt.axvline(30,  color='r', linestyle='--')\n",
    "plt.axvline(120, color='r', linestyle='--')\n",
    "plt.title(f\"neural activity for trial {trial_id_1}, orientation = {stim[trial_id_1]}\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(neural_data_norm[neuron_id,stim_on_aligned[trial_id_2]-30:stim_off_aligned[trial_id_2]+30])\n",
    "plt.axvline(30,  color='r', linestyle='--')\n",
    "plt.axvline(120, color='r', linestyle='--')\n",
    "plt.title(f\"neural activity for trial {trial_id_2}, orientation = {stim[trial_id_2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604b1b1",
   "metadata": {},
   "source": [
    "Since the orientation of stimulus is randomized across time during experiment, we need to extract the neural activity for same direction trials to calculate the tuning curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the neural activity for same direction trials\n",
    "# here is the example how to extract all trials for orientation = 0 \n",
    "stim_on_aligned_0 =stim_on_aligned[stim==0]\n",
    "stim_off_aligned_0 =stim_off_aligned[stim==0]\n",
    "\n",
    "neural_data_0 = []\n",
    "for tr in range(len(stim_on_aligned_0)):\n",
    "    neural_data_0.append(neural_data_norm[:, stim_on_aligned_0[tr]-30:stim_off_aligned_0[tr]+30])\n",
    "neural_data_0 = np.array(neural_data_0)\n",
    "\n",
    "np.shape(neural_data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_id = 0\n",
    "for tr in range(len(neural_data_0)):\n",
    "    plt.plot(neural_data_0[tr][neuron_id,:], color='gray', alpha=0.5)\n",
    "plt.plot(np.average(neural_data_0[:,neuron_id,:], axis=0), color='r', linewidth=2)\n",
    "plt.axvline(30,  color='r', linestyle='--')\n",
    "plt.axvline(120, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134becc",
   "metadata": {},
   "source": [
    "### Task3: extracting the neural activity of same direction trials for all orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7de482-43e2-4222-a86d-7b7a68fc9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your own code\n",
    "### hint: loop above example code for all orientations\n",
    "\n",
    "\n",
    "orientations = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]\n",
    "\n",
    "#/.../\n",
    "\n",
    "np.shape(neural_data_all_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a13857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the trial-averaged trace of neuron 0 for all orientations respectively\n",
    "# neuron_id = 3\n",
    "plt.figure(figsize=(10,5))\n",
    "for i, ori in enumerate(orientations):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.plot(np.average(neural_data_all_ori[i][:,neuron_id,:], axis=0))\n",
    "    plt.axvline(30,  color='r', linestyle='--')\n",
    "    plt.axvline(120, color='r', linestyle='--')\n",
    "    plt.title(f\"orientation = {ori}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80a9de-646f-4eec-a041-a0088e840ffe",
   "metadata": {},
   "source": [
    "# 4. orientation tuning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9f8f3",
   "metadata": {},
   "source": [
    "to quantify the neural activity induced by grating stimulus, we can subtract the baseline activity from the activity trace. Here we consider the average activity of 1s window before stimulus as baseline. Then the neural activity level during stimulation across different direction is comparable. Therefore, we take the mean value of each averaged neural trace during stimulus (from frame 30 to 120). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract baseline\n",
    "# neuron_id = 59\n",
    "\n",
    "avg_activity_n = []\n",
    "for i in range(len(orientations)):\n",
    "    # Compute the baseline: average of the first 30 frames\n",
    "    avg_trace = np.average(neural_data_all_ori[i][:,neuron_id,:], axis=0)\n",
    "    baseline = np.mean(avg_trace[:30])\n",
    "\n",
    "    normalized_avg_trace = avg_trace - baseline\n",
    "    avg_activity_n.append(normalized_avg_trace)\n",
    "    \n",
    "avg_activity_n = np.array(avg_activity_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fe60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i, ori in enumerate(orientations):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.plot(avg_activity_n[i])\n",
    "    plt.axvline(30,  color='r', linestyle='--')\n",
    "    plt.axvline(120, color='r', linestyle='--')\n",
    "    plt.title(f\"orientation = {ori}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce9776",
   "metadata": {},
   "source": [
    "### Task4.1: calculate the orientation response for all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2776731",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your own code\n",
    "### hint1: looping the above code for all neurons: calculate the average activity for each orientation, then subtract the baseline.\n",
    "### hint2: take the mean value of trial-averaged neural trace during stimulus (i.e. from frame 30 to frame 120), to get one number for each neuron and each orientation.\n",
    "### hint3: The target array should have shape (526*12)\n",
    "\n",
    "\n",
    "#/.../\n",
    "\n",
    "\n",
    "\n",
    "avg_ori_response_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b40511",
   "metadata": {},
   "source": [
    "#### Visualizing the orientation tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_MG_radar(orientations, response, neuron_id):\n",
    "    # Initialize the radar plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Compute angle of each axis\n",
    "    orientations_rad = np.deg2rad(orientations)\n",
    "    orientations_rad = np.concatenate([orientations_rad, orientations_rad[:1]], axis=0)\n",
    "\n",
    "\n",
    "    response_cir = np.concatenate([response, response[:1]], axis=0)\n",
    "\n",
    "    # Draw one axe per variable and add labels\n",
    "    ax.set_theta_offset(np.pi)  # Rotate the chart by 90° counterclockwise\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw the outline of the radar chart\n",
    "    ax.plot(orientations_rad, response_cir, linewidth=1, linestyle='solid', color='darkorange')\n",
    "    ax.fill(orientations_rad, response_cir, alpha=0.2, color='darkorange')\n",
    "\n",
    "    # Add ticks, labels and limits\n",
    "    ax.set_xticks(orientations_rad)\n",
    "    ax.set_title(f\"neuron_id = {neuron_id}\")\n",
    "    \n",
    "    labels = [str(orientation)+\"°\" for orientation in orientations]\n",
    "    labels += labels[:1]\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylim(-1, max(response_cir)+0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c14e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for neuron in range(5):\n",
    "    plot_MG_radar(orientations, (avg_ori_response_all[neuron]), neuron)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba89c83",
   "metadata": {},
   "source": [
    "#### Quantifying orientation selectivity\n",
    "After visualizing the neural activity corresponding to each orientation, we also want to quantify the orientation selectivity of each neuron by calculating the OSI (orientation selectivity index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a638ae",
   "metadata": {},
   "source": [
    "The **Orientation Selectivity Index (OSI)** quantifies how selective a neuron is to specific orientations (Mazurek et al., 2014)\n",
    "\n",
    "The OSI is calculated as:\n",
    "$$\n",
    "\\text{OSI} = \\frac{\\left| \\sum R(\\theta_i) e^{i \\theta_i} \\right|}{\\sum \\left| R(\\theta_i) \\right|}\n",
    "$$\n",
    "where $\\theta_i$ is the grating orientations  (e.g., $0^\\circ, 30^\\circ, \\dots, 180^\\circ$);  $R(\\theta_i)$ is the response for each orientation. $e^{i \\theta_i}$ represents the unit vector in the direction $\\theta_i$, \n",
    "\n",
    "\n",
    "- $\\text{OSI} = 0$: Non-selective response.\n",
    "- $\\text{OSI} = 1$: Perfectly selective to one orientation.\n",
    "\n",
    "The preferred orientation is calculated by:\n",
    "$$\n",
    "\\theta_{\\text{pref}} = \\arg(\\mathbf{V}_{\\text{mean}})\n",
    "$$\n",
    "where $\\arg$ is the angle of the mean vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_osi(orientations, response):\n",
    "\n",
    "    # Collapse orientations into 0 to 180 degrees\n",
    "    collapsed_orientations = np.array(orientations) % 180  # Map 180°-apart directions to the same value\n",
    "    unique_orientations, indices = np.unique(collapsed_orientations, return_inverse=True)\n",
    "\n",
    "    # Sum responses for equivalent orientations\n",
    "    collapsed_responses = np.zeros_like(unique_orientations, dtype=float)\n",
    "    for i in range(len(unique_orientations)):\n",
    "        collapsed_responses[i] = np.sum(response[indices == i])\n",
    "\n",
    "    # Convert unique orientations to radians\n",
    "    unique_orientations_rad = np.deg2rad(unique_orientations)\n",
    "\n",
    "    # Compute the vector sum\n",
    "    vector_sum = np.sum(collapsed_responses * np.exp(1j * unique_orientations_rad))\n",
    "\n",
    "    # Calculate OSI: magnitude of vector sum divided by total response\n",
    "    osi = np.abs(vector_sum) / np.sum(np.abs(collapsed_responses))\n",
    "\n",
    "    # Calculate the preferred orientation\n",
    "    pref_ori_rad = np.angle(vector_sum)  # Angle in radians\n",
    "    pref_ori_deg = np.rad2deg(pref_ori_rad) % 180  # Normalize to [0, 180)\n",
    "\n",
    "    return osi, pref_ori_deg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_id = 0\n",
    "osi, pref_ori_deg = compute_osi(orientations, avg_ori_response_all[neuron_id])\n",
    "osi, pref_ori_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed978d",
   "metadata": {},
   "source": [
    "### Task4.2: select some neurons, calculate the OSI and preferred orientation angle. Try to interprete the calculated results together with radar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a028d-596b-43c2-ad9f-6392e15b3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the OSI and preferred orientation angle for other neurons\n",
    "### write your own code\n",
    "\n",
    "#/.../\n",
    "\n",
    "print(f\"neuron_id = {neuron_id}, OSI = {osi}, preferred orientation = {pref_ori_deg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e5162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c51a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
